# ğŸ¯ T1D PINN MLOps Production Stack

## ğŸ“‹ Overview

Complete production-grade MLOps infrastructure for Type 1 Diabetes glucose prediction and parameter estimation using Physics-Informed Neural Networks.

**Inspired by:** J0MT/AI_Drug_Discovery repository structure  
**Adapted for:** Medical AI with safety-critical glucose prediction  

---

## ğŸ—ï¸ Project Structure

```
T1D_PINN_Project/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci-test.yml              # Continuous integration testing
â”‚       â”œâ”€â”€ train-models.yml         # Automated model training
â”‚       â””â”€â”€ deploy-mlflow.yml        # MLflow deployment
â”‚
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf                      # AWS infrastructure definition
â”‚   â”œâ”€â”€ variables.tf                 # Configuration variables
â”‚   â”œâ”€â”€ outputs.tf                   # Infrastructure outputs
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ ec2/                     # EC2 instance configuration
â”‚       â”œâ”€â”€ s3/                      # S3 bucket for results
â”‚       â””â”€â”€ iam/                     # IAM roles and policies
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                   # Main training container
â”‚   â”œâ”€â”€ docker-compose.yml           # Multi-service orchestration
â”‚   â”œâ”€â”€ mlflow/
â”‚   â”‚   â””â”€â”€ Dockerfile              # MLflow tracking server
â”‚   â””â”€â”€ airflow/
â”‚       â””â”€â”€ Dockerfile              # Airflow orchestration
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ comprehensive_training.py    # Batch experiment orchestration
â”‚       â”œâ”€â”€ model_comparison.py          # Cross-model evaluation
â”‚       â””â”€â”€ real_patient_pipeline.py     # Real data processing
â”‚
â”œâ”€â”€ mlflow/
â”‚   â”œâ”€â”€ mlflow_config.py            # MLflow integration utilities
â”‚   â””â”€â”€ model_registry.py           # Model versioning logic
â”‚
â”œâ”€â”€ dvc/
â”‚   â”œâ”€â”€ .dvc/                       # DVC configuration
â”‚   â”œâ”€â”€ .dvcignore                  # Files to ignore
â”‚   â””â”€â”€ data.dvc                    # Data version tracking
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                     # Model architectures (existing)
â”‚   â”œâ”€â”€ datasets/                   # Data loaders (existing)
â”‚   â”œâ”€â”€ training/                   # Training logic (existing)
â”‚   â”œâ”€â”€ physics/                    # Physics constraints (existing)
â”‚   â””â”€â”€ utils/                      # Utilities (existing)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_forward.py            # Forward training (existing)
â”‚   â”œâ”€â”€ train_inverse.py            # Inverse training (existing)
â”‚   â”œâ”€â”€ visualise.py                # Visualization (existing)
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluation (existing)
â”‚   â””â”€â”€ batch_experiments.py        # NEW: Batch runner
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                       # Unit tests
â”‚   â”œâ”€â”€ integration/                # Integration tests
â”‚   â””â”€â”€ conftest.py                 # Pytest configuration
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ birnn_forward.yaml          # Existing configs
â”‚   â”œâ”€â”€ pinn_inverse.yaml           # Existing configs
â”‚   â””â”€â”€ experiment_matrix.yaml      # NEW: Batch experiment config
â”‚
â”œâ”€â”€ data/                           # (Tracked by DVC)
â”‚   â”œâ”€â”€ synthetic/                  # Synthetic patient data
â”‚   â””â”€â”€ processed/                  # Real patient data
â”‚
â”œâ”€â”€ results/                        # (Backed up to S3)
â”‚   â””â”€â”€ [experiment outputs]
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SETUP_GUIDE.md              # Infrastructure setup
â”‚   â”œâ”€â”€ MLOPS_WORKFLOW.md           # Usage guide
â”‚   â””â”€â”€ API_REFERENCE.md            # Code documentation
â”‚
â”œâ”€â”€ .gitignore                      # Git ignore patterns
â”œâ”€â”€ .dockerignore                   # Docker ignore patterns
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ setup.py                        # Package installation
â”œâ”€â”€ pytest.ini                      # Pytest configuration
â”œâ”€â”€ .flake8                         # Linting configuration
â”œâ”€â”€ .pre-commit-config.yaml         # Pre-commit hooks
â””â”€â”€ README.md                       # Project documentation
```

---

## ğŸ› ï¸ Technology Stack

### ML & Data
- **PyTorch**: Deep learning framework (BI-RNN, PINN, Modified-MLP)
- **DeepXDE**: Physics-Informed Neural Networks
- **MLflow**: Experiment tracking, model registry, artifact management
- **DVC**: Data versioning with S3 backend
- **Pandas, NumPy**: Data processing and feature engineering

### Infrastructure & DevOps
- **AWS EC2 + Terraform**: Infrastructure as Code deployment
- **Docker + Docker Compose**: Containerized services with network orchestration
- **GitHub Container Registry**: Private image storage and distribution
- **GitHub Actions**: CI/CD with automated model training triggers
- **AWS S3**: Results storage and DVC remote

### Orchestration & Workflow
- **Apache Airflow**: DAG-based experiment orchestration
- **tmux/screen**: Multi-experiment parallelization

### Development & Quality
- **pytest**: Comprehensive unit and integration testing
- **black, flake8**: Code formatting and linting
- **Type hints**: Static type checking for reliability
- **YAML configs**: Declarative hyperparameter management

---

## ğŸš€ Quick Start

### Prerequisites
- AWS Account (free tier eligible)
- Docker Desktop installed
- Git configured
- Python 3.9+

### 1. Clone and Setup
```bash
git clone https://github.com/YOUR_USERNAME/T1D_PINN_Project.git
cd T1D_PINN_Project

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -e .
```

### 2. Configure AWS Credentials
```bash
aws configure
# Enter your AWS Access Key ID
# Enter your AWS Secret Access Key
# Enter region: eu-west-2 (or your preferred region)
```

### 3. Build Docker Images
```bash
docker-compose build
```

### 4. Deploy Infrastructure
```bash
cd terraform
terraform init
terraform plan
terraform apply
```

### 5. Start Services
```bash
docker-compose up -d
# MLflow UI: http://localhost:5000
# Airflow UI: http://localhost:8080
```

### 6. Run First Experiment
```bash
# Local test
python scripts/train_inverse.py --config configs/pinn_inverse.yaml --patient 3

# Via Docker
docker-compose run training python scripts/train_inverse.py --config configs/pinn_inverse.yaml --patient 3

# Via Airflow (batch)
# Navigate to http://localhost:8080 and trigger DAG
```

---

## ğŸ“Š Experiment Workflows

### Single Experiment
```bash
# Local execution
python scripts/train_inverse.py \
    --config configs/pinn_inverse.yaml \
    --patient 3 \
    --inverse-params ksi
```

### Batch Experiments (All Models Ã— All Patients)
```bash
# Via Airflow DAG
airflow dags trigger comprehensive_training

# Or via script
python scripts/batch_experiments.py \
    --models birnn pinn modified_mlp \
    --patients 2 3 4 5 6 7 8 9 10 11 \
    --parallel 5
```

### View Results
```bash
# MLflow UI
open http://localhost:5000

# Or query programmatically
python -c "
import mlflow
client = mlflow.tracking.MlflowClient()
experiments = client.list_experiments()
for exp in experiments:
    print(f'{exp.name}: {exp.experiment_id}')
"
```

---

## ğŸ¥ Medical AI Considerations

### Safety & Validation
- âœ… Comprehensive testing on synthetic data before real patients
- âœ… Parameter estimation error tracking (<5% target)
- âœ… Prediction RMSE monitoring (<5 mg/dL target)
- âœ… Physics constraint validation (ODE residuals)

### Reproducibility
- âœ… All experiments tracked in MLflow
- âœ… Data versioned with DVC
- âœ… Infrastructure versioned with Terraform
- âœ… Container images tagged and stored

### Compliance
- âœ… No PHI in version control
- âœ… Encrypted data storage (S3 + encryption)
- âœ… Audit trail via MLflow
- âœ… Reproducible pipelines for regulatory review

---

## ğŸ“ˆ Results Organization

### Experiment Naming Convention
```
{model}_{mode}_{patient}_ksi_{timestamp}/
```

Example:
```
pinn_inverse_Pat3_ksi_20251129_143022/
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ predictions.npz
â”œâ”€â”€ parameter_evolution_ksi.npz
â””â”€â”€ metadata.json
```

### MLflow Organization
```
Experiments/
â”œâ”€â”€ BIRNN_Forward/
â”œâ”€â”€ BIRNN_Inverse/
â”œâ”€â”€ PINN_Forward/
â”œâ”€â”€ PINN_Inverse/
â”œâ”€â”€ ModifiedMLP_Forward/
â””â”€â”€ ModifiedMLP_Inverse/
```

---

## ğŸ¯ Next Steps

1. **Week 1**: Set up infrastructure (Docker, Terraform, GitHub Actions)
2. **Week 2**: Integrate MLflow tracking into existing code
3. **Week 3**: Build Airflow DAGs for batch experiments
4. **Week 4**: Run comprehensive evaluation (all models Ã— all patients)
5. **Week 5**: Collect results, generate visualizations, write paper

---

## ğŸ“š Documentation

- **[SETUP_GUIDE.md](docs/SETUP_GUIDE.md)** - Detailed setup instructions
- **[MLOPS_WORKFLOW.md](docs/MLOPS_WORKFLOW.md)** - Day-to-day usage
- **[TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** - Common issues
- **[API_REFERENCE.md](docs/API_REFERENCE.md)** - Code documentation

---

## ğŸ¤ Contributing

This is a research project for Type 1 Diabetes closed-loop control. Contributions welcome!

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

- **MLOps Structure**: Inspired by J0MT/AI_Drug_Discovery
- **Physics Model**: Based on Magdelaine et al. 2015
- **Research Group**: Imperial College London, Biomedical Engineering

---

## ğŸ“§ Contact

**Harsh [Your Last Name]**  
Imperial College London  
Email: [your-email]@imperial.ac.uk  
GitHub: @[your-github-username]

---

**Status**: ğŸš§ In Development | ğŸ“Š Paper in Progress | ğŸ¯ Production-Ready MLOps
